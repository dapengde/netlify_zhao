<meta charset="utf-8">

**Regression**
 Supplement
 Dr. Peng Zhao






(#) Linear regression line





~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
b <- sum((dtf$gaokao - mean_gaokao) * (dtf$env - mean_env)) / 
  sum((dtf$gaokao - mean_gaokao) ^ 2)
b
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 0.653667
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
a <- mean_env - b * mean_gaokao
a
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 23.02987
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Now I can predict an ENV203 student's score with:

$$\text{ENV SCORE} = 23 + 0.65 \times \text{GAOKAO SCORE}$$

(#) Variation around the regression line


~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
dtf$predicted <- a + b * dtf$gaokao
dtf$residual <- dtf$env - dtf$predicted
~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
knitr::kable(dtf)
~~~~~~~~~~~~~~~~~~~~~~~~~~~



| id| env| gaokao| predicted|   residual|
|--:|---:|------:|---------:|----------:|
|  1|  56|     45|  52.44489|   3.555115|
|  2|  74|     81|  75.97690|  -1.976899|
|  3|  56|     65|  65.51823|  -9.518226|
|  4|  81|     87|  79.89890|   1.101099|
|  5|  75|     68|  67.47923|   7.520773|
|  6|  84|     91|  82.51357|   1.486431|
|  7|  68|     77|  73.36223|  -5.362231|
|  8|  52|     61|  62.90356| -10.903558|
|  9|  57|     55|  58.98156|  -1.981556|
| 10|  82|     66|  66.17189|  15.828107|
| 11|  73|     82|  76.63057|  -3.630566|
| 12|  90|     93|  83.82090|   6.179097|
| 13|  67|     76|  72.70856|  -5.708564|
| 14|  79|     83|  77.28423|   1.715767|
| 15|  70|     61|  62.90356|   7.096442|
| 16|  66|     74|  71.40123|  -5.401230|



~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
summary(dtf$residual)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -10.9036  -5.3720  -0.4379   0.0000   4.2111  15.8281
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
syx <- sqrt(sum(dtf$residual ^ 2) / (nrow(dtf) - 2))
syx
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 7.248895
~~~~~~~~~~~~~~~~~~~~~~~~~~~

(#) Hypothesis test about fit

Table:


~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
# df
N <- nrow(dtf)
(dftot <- N - 1)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 15
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(dfres <- N - 2)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 14
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(dfreg <- 1)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 1
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
dftot - dfres
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 1
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
# SS
(SStot <- sum((dtf$env - mean_env) ^ 2))
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 1899.75
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(SSres <- sum((dtf$env - dtf$predicted) ^2))
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 735.6507
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(SSreg <- sum((dtf$predicted - mean_env) ^ 2))
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 1164.099
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
SSreg + SSres
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 1899.75
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
# MS
(MSreg <- SSreg / dfreg)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 1164.099
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(MSres <- SSres / dfres)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 52.54648
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
# F
(F_score <- MSreg / MSres)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 22.15371
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(F_critical <- qf(0.05, df1 = dfreg, df2 = dfres, lower.tail = FALSE))
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 4.60011
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
pf(F_score, df1 = dfreg, df2 = dfres, lower.tail = FALSE)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 0.0003368488
~~~~~~~~~~~~~~~~~~~~~~~~~~~


| Source                                    | $df$  | $SS$   | $MS$  | $F$  |
| ----------------------------------------- | ----- | ------ | ----- | ---- |
| between the point and the mean            | 15      | 1899.75       |        |   |
| between the point and the regression line | 14      | 735.6507077       |  52.5464791     |   |
| between the regression line and the mean  | 1      | 1164.0992923       |  1164.0992923     |  22.1537068 |

Decision.

With 1 and 14  degrees of freedom and $\alpha = 0.05$, the critical value of $F$ is 4.6001099. The calculated $F$ (22.1537068) is greater than the critical $F$, so the decision is to reject $H_0$. We can conclude that the regression line provides a good fit to the data in the sample.s|

(#) Hypothesis test about the slope



~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
syx
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 7.248895
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(sx <- sd(dtf$gaokao))
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 13.47699
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(sb <- syx/(sx * sqrt(N-1)))
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 0.138878
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
beta <- 0
b
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 0.653667
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(t_score <- (b-beta) /sb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 4.706772
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(t_critical <- qt(0.975, df = N-2))
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 2.144787
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
pt(t_score, df = N - 2, lower.tail = FALSE) * 2
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 0.0003368488
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Decision.

With 14  degrees of freedom and $\alpha = 0.05$, the critical value of $t$ is 2.1447867. The calculated $t$ (4.7067724) is greater than the critical $t$, so the decision is to reject $H_0$. We can conclude that the slope of the regression line is not equal to 0.

(#) Hypothesis test about the intercept


~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
syx
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 7.248895
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
N
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 16
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(xbar <- mean_gaokao)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 72.8125
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
sx
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 13.47699
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(sa <- syx * sqrt(1/N + xbar ^2 / ((N-1) * sx^2)))
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 10.27316
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
alpha <- 0
a
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 23.02987
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(t_score <- (a-alpha) /sa)
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 2.241752
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
(t_critical <- qt(0.975, df = N-1))
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 2.13145
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~r linenumbers
pt(t_score, df = N - 2, lower.tail = FALSE) * 2
~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
## [1] 0.04169709
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Decision.

With 15  degrees of freedom and $\alpha = 0.05$, the critical value of $t$ is 2.1314495. The calculated $t$ (2.2417517) is greater than the critical $t$, so the decision is to reject $H_0$. We can conclude that the intercept of the regression line is not equal to 0.
<!-- Markdeep js: -->
<script src="D:/Program Files/R/R-4.0.1/library/deepdown/js/deepdown-doc.js" charset="utf-8"></script>
<script>markdeepOptions={inlineCodeLang:"R", tocStyle:"short"};</script>

<!-- FALLBACK: -->
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>

<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>

<!-- Inverse the color: -->
<style>
.md .inverse svg.diagram {
  background: #333;
  stroke: #FFF;
  fill: #FFF;
}

.md .inverse svg.diagram .opendot {
  fill: #333;
}
</style>

<!-- Markdeep: --><style class="fallback">body{visibility:hidden}</style><script src="https://pzhao.org/js/deepdown-doc.js?" charset="utf-8"></script>
